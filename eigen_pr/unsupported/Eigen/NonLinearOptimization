// This file is part of Eigen, a lightweight C++ template library
// for linear algebra.
//
// Copyright (C) 2009 Thomas Capricelli <orzel@freehackers.org>
//
// This Source Code Form is subject to the terms of the Mozilla
// Public License v. 2.0. If a copy of the MPL was not distributed
// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.

#ifndef EIGEN_NONLINEAROPTIMIZATION_MODULE
#define EIGEN_NONLINEAROPTIMIZATION_MODULE

#include <vector>

#include <Eigen/Core>
#include <Eigen/Jacobi>
#include <Eigen/QR>
#include <unsupported/Eigen/NumericalDiff>

/**
  * \defgroup NonLinearOptimization_Module Non linear optimization module
  *
  * \code
  * #include <unsupported/Eigen/NonLinearOptimization>
  * \endcode
  *
  * This module provides implementation of Powell's hybrid "dogleg" method
  * to find zeros of vector-valued functions.
  *
  * This code is a port of minpack (http://en.wikipedia.org/wiki/MINPACK).
  * Minpack is a very famous, old, robust and well-reknown package, written in 
  * fortran. Those implementations have been carefully tuned, tested, and used
  * for several decades.
  *
  * The original fortran code was automatically translated using f2c (http://en.wikipedia.org/wiki/F2c) in C,
  * then c++, and then cleaned by several different authors.
  * The last one of those cleanings being our starting point : 
  * http://devernay.free.fr/hacks/cminpack.html
  * 
  * Finally, we ported this code to Eigen, creating classes and API
  * coherent with Eigen. When possible, we switched to Eigen
  * implementation, such as most linear algebra (vectors, matrices, stable norms).
  *
  * Doing so, we were very careful to check the tests we setup at the very
  * beginning, which ensure that the same results are found.
  *
  * \section Tests Tests
  * 
  * The tests are placed in the file unsupported/test/NonLinear.cpp.
  * 
  * There are two kinds of tests : those that come from examples bundled with cminpack.
  * They guarantee we get the same results as the original algorithms (value for 'x',
  * for the number of evaluations of the function, and for the number of evaluations
  * of the jacobian if ever).
  * 
  * 
  * The documentation for running the tests is on the wiki
  * http://eigen.tuxfamily.org/index.php?title=Tests
  * 
  * \section API API : overview of methods
  * 
  * The algorithm can use either the jacobian (provided by the user) or compute 
  * an approximation by itself (actually using Eigen \ref NumericalDiff_Module).
  * The part of API referring to the latter use 'NumericalDiff' in the method names
  * (exemple: HybridNonLinearSolver.minimizeNumericalDiff() ) 
  * 
  * All algorithms are provided using Two APIs :
  *     - one where the user inits the algorithm, and uses '*OneStep()' as much as he wants : 
  * this way the caller have control over the steps
  *     - one where the user just calls a method (optimize() or solve()) which will 
  * handle the loop: init + loop until a stop condition is met. Those are provided for
  *  convenience.
  * 
  * As an example, the method HybridNonLinearSolver::minimize() is 
  * implemented as follow : 
  * \code
  * Status HybridNonLinearSolver<FunctorType,Scalar>::minimize(FVectorType  &x, const int mode)
  * {
  *     Status status = minimizeInit(x, mode);
  *     do {
  *         status = minimizeOneStep(x, mode);
  *     } while (status==Running);
  *     return status;
  * }
  * \endcode
  * 
  * \section examples Examples
  * 
  * The easiest way to understand how to use this module is by looking at the many examples in the file
  * unsupported/test/NonLinearOptimization.cpp.
  */

#ifndef EIGEN_PARSED_BY_DOXYGEN

#include "src/NonLinearOptimization/r1updt.h"
#include "src/NonLinearOptimization/r1mpyq.h"
#include "src/NonLinearOptimization/rwupdt.h"
#include "src/NonLinearOptimization/fdjac1.h"
#include "src/NonLinearOptimization/dogleg.h"

#include "src/NonLinearOptimization/chkder.h"

#endif

#include "src/NonLinearOptimization/HybridNonLinearSolver.h"


#endif // EIGEN_NONLINEAROPTIMIZATION_MODULE
